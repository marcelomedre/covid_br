library(ggplot2)
library(wordcloud)
library(data.table)
library(tidytext)
library(stringr)
library(dplyr)
## store api keys (these are fake example values; replace with your own keys)
api_key <- "7SyT9OG6lG7q1xmWZO0IN4ohG"
api_secret_key <- "8zfSoJXSBt2S8ExfGkzEr3cHHHcgdjQ74tXGGudNW6kBF4Gwbp"
access_token <- "466470207-ussLd7rz2uLAkFN4JF6uN7Gu1nWJYeaFk5Xdhliq"
access_token_secret <- "2SfcWJDaza5a2T6Z14OQt9faaAzqVbx8C5hDoxG5DZXIT"
## authenticate via web browser
token <- create_token(
app = "rstatsjournalismresearch",
consumer_key = api_key,
consumer_secret = api_secret_key,
access_token = access_token,
access_secret = access_token_secret)
## search for 18000 tweets using the rstats hashtag
rt <- search_tweets(
"Covid-19", n = 180, include_rts = FALSE, lookup_coords("brasil"), type = 'recent'
)
shiny::runApp('C:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br')
runApp('C:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br')
runApp('C:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br')
runApp('C:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br')
new_ct_ob_choice <- covid %>%
filter(place_type == "city") %>%
filter(state == "Londrina") %>%
group_by(date) %>%
summarise(n = sum(last_available_deaths)) %>%
arrange(date) %>%
mutate(new = (c(0, diff(n))))
library(rvest)
library(ggplot2)
library(plotly)
library(lubridate)
library(scales)
library(plotly)
library(geobr)
library(sf)
library(dplyr)
library(car)
library(chron)
library(TTR)
url <- "https://brasil.io/dataset/covid19/caso_full/?format=csv"
covid <- read.csv(file=url, encoding = "UTF-8")
covid$date <- as.Date(covid$date)
new_ct_ob_choice <- covid %>%
filter(place_type == "city") %>%
filter(state == "Londrina") %>%
group_by(date) %>%
summarise(n = sum(last_available_deaths)) %>%
arrange(date) %>%
mutate(new = (c(0, diff(n))))
View(new_ct_ob_choice)
new_ct_ob_choice <- covid %>%
filter(place_type == "city") %>%
filter(state == "Londrina") %>%
group_by(date) %>%
summarise(n = sum(last_available_deaths))
View(covid)
new_ct_ob_choice <- covid %>%
filter(place_type == "city") %>%
filter(city == "Londrina") %>%
group_by(date) %>%
summarise(n = sum(last_available_deaths))
## search for 18000 tweets using the rstats hashtag
rt <- search_tweets(
"Covid-19", n = 180, include_rts = FALSE, lookup_coords("brasil"), type = 'recent'
)
## search for 18000 tweets using the rstats hashtag
rt <- search_tweets(
"Covid-19", n = 180, include_rts = FALSE, lookup_coords("brasil")
)
## search for 18000 tweets using the rstats hashtag
rt <- search_tweets(
"Covid-19", n = 180, include_rts = FALSE
)
## check to see if the token is loaded
#library(rtweet)
#get_token()
lookup_coords(address = "brazil")
## check to see if the token is loaded
#library(rtweet)
#get_token()
t <- lookup_coords(address = "brazil")
View(t)
## search for 18000 tweets using the rstats hashtag
rt <- search_tweets(
"Covid-19", n = 180, include_rts = FALSE, geocode = t
)
API_google <- "AIzaSyAH1kUPAqDfOyw9wU_8V8eEkj-Ql9CGJX8AIzaSyAH1kUPAqDfOyw9wU_8V8eEkj-Ql9CGJX8"
## check to see if the token is loaded
#library(rtweet)
#get_token()
t <- lookup_coords(address = "brazil", apikey = API_google)
View(t)
## search for 18000 tweets using the rstats hashtag
rt <- search_tweets(
"Covid-19", n = 180, include_rts = FALSE, geocode = t
)
## check to see if the token is loaded
#library(rtweet)
#get_token()
t <- lookup_coords(address = "brasil", apikey = API_google)
View(t)
rtweet:::find_google_geocode_key()
## check to see if the token is loaded
#library(rtweet)
#get_token()
t <- lookup_coords(address = "brasil", apikey = rtweet:::find_google_geocode_key())
View(t)
## check to see if the token is loaded
#library(rtweet)
#get_token()
## search for 18000 tweets using the rstats hashtag
rt <- search_tweets(
"Covid-19", n = 180, include_rts = FALSE, geocode = t
)
sentiment=sentiment_by(rt$text)
## check to see if the token is loaded
#library(rtweet)
#get_token()
## search for 18000 tweets using the rstats hashtag
rt <- search_tweets(
"Covid-19", n = 180, include_rts = FALSE
)
sentiment=sentiment_by(rt$text)
summary(sentiment$ave_sentiment)
qplot(sentiment$ave_sentiment,   geom="histogram",binwidth=0.1,main="Review Sentiment Histogram")
fig30 <- qplot(sentiment$ave_sentiment,   geom="histogram",
binwidth=0.1, main="Review Sentiment Histogram")
## plot time series of tweets
rt %>%
ts_plot("1 min") +
ggplot2::theme_minimal() +
ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +
ggplot2::labs(
x = NULL, y = NULL,
title = "Frequency of Covid-19 Twitter statuses from past 18k tweets",
subtitle = "Twitter status (tweet) counts aggregated using one-min intervals",
caption = "\nSource: Data collected from Twitter's REST API via rtweet"
)
df$ave_sentiment=sentiment$ave_sentiment
## plot time series of tweets
rt %>%
ts_plot("1 min") +
ggplot2::theme_minimal() +
ggplot2::theme(plot.title = ggplot2::element_text(face = "bold")) +
ggplot2::labs(
x = NULL, y = NULL,
title = "Frequency of Covid-19 Twitter statuses from past 18k tweets",
subtitle = "Twitter status (tweet) counts aggregated using one-min intervals",
caption = "\nSource: Data collected from Twitter's REST API via rtweet"
)
df$ave_sentiment=sentiment$ave_sentiment
df$sd_sentiment=sentiment$sd
mytext <- get_sentences(rt$text)
sentiment(mytext)
sentiment(rt$text)
pol_words <- extract_sentiment_terms(mytext)
pol_words
pol_words$sentence
pol_words$neutral
data.table::as.data.table(pol_words)
attributes(extract_sentiment_terms(mytext))$counts
attributes(extract_sentiment_terms(mytext))$elements
#wordcloud
sentiment_counts <- attributes(pol_words)$counts
sentiment_counts[polarity > 0,]
par(mfrow = c(1, 3), mar = c(0, 0, 0, 0))
## Positive Words
with(
sentiment_counts[polarity > 0,],
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"), scale = c(4.5, .75)
)
)
mtext("Positive Words", side = 3, padj = 5)
## Negative Words
with(
sentiment_counts[polarity < 0,],
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"), scale = c(4.5, 1)
)
)
mtext("Negative Words", side = 3, padj = 5)
sentiment_counts[,
color := ifelse(polarity > 0, 'red',
ifelse(polarity < 0, 'blue', 'gray70')
)]
## Positive & Negative Together
with(
sentiment_counts[polarity != 0,],
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35,
colors = color, ordered.colors = TRUE, scale = c(5, .75)
)
)
par(mfrow = c(3, 1), mar = c(0, 0, 0, 0))
## Positive Words
fig30 <- with(
sentiment_counts[polarity > 0,],
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"), scale = c(4.5, .75)
)
)
mtext("Positive Words", side = 3, padj = 5)
## Negative Words
with(
sentiment_counts[polarity < 0,],
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"), scale = c(4.5, 1)
)
)
mtext("Negative Words", side = 3, padj = 5)
sentiment_counts[,
color := ifelse(polarity > 0, 'red',
ifelse(polarity < 0, 'blue', 'gray70')
)]
## Positive & Negative Together
with(
sentiment_counts[polarity != 0,],
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35,
colors = color, ordered.colors = TRUE, scale = c(5, .75)
)
)
mtext("Positive (red) & Negative (blue) Words", side = 3, padj = 5)
## Negative Words
with(
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"), scale = c(4.5, 1)
)
)
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"), scale = c(4.5, 1)
)
## Positive Words
fig30 <- with(
sentiment_counts[polarity > 0,],
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"), scale = c(4.5, .75)
)
)
## Positive Words
pos_words <- sentiment_counts[polarity > 0,]
fig30 <- wordcloud(words = pos_words, freq = n, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"), scale = c(4.5, .75)
)
fig30 <- wordcloud(words = pos_words, freq = n, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"), scale = c(4.5, .75))
View(pos_words)
sentiment=sentiment_by(rt$text)
summary(sentiment$ave_sentiment)
mytext <- get_sentences(rt$text)
sentiment(mytext)
sentiment(rt$text)
mytext <- get_sentences(rt$text)
sentiment(mytext)
sentiment(rt$text)
pol_words <- extract_sentiment_terms(mytext)
pol_words
pol_words$sentence
pol_words$neutral
data.table::as.data.table(pol_words)
attributes(extract_sentiment_terms(mytext))$counts
attributes(extract_sentiment_terms(mytext))$elements
#wordcloud
sentiment_counts <- attributes(pol_words)$counts
sentiment_counts[polarity > 0,]
par(mfrow = c(1, 3), mar = c(0, 0, 0, 0))
## Positive Words
with(
sentiment_counts[polarity > 0,],
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"), scale = c(4.5, .75)
)
)
mtext("Positive Words", side = 3, padj = 5)
## Negative Words
with(
sentiment_counts[polarity < 0,],
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 200, random.order = FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"), scale = c(4.5, 1)
)
)
mtext("Negative Words", side = 3, padj = 5)
sentiment_counts[,
color := ifelse(polarity > 0, 'red',
ifelse(polarity < 0, 'blue', 'gray70')
)]
## Positive Words
with(
sentiment_counts[polarity > 0,],
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 500, random.order = FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"), scale = c(4.5, .75)
)
)
mtext("Positive Words", side = 3, padj = 5)
## Negative Words
with(
sentiment_counts[polarity < 0,],
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 500, random.order = FALSE, rot.per = 0.35,
colors = brewer.pal(8, "Dark2"), scale = c(4.5, 1)
)
)
mtext("Negative Words", side = 3, padj = 5)
sentiment_counts[,
color := ifelse(polarity > 0, 'red',
ifelse(polarity < 0, 'blue', 'gray70')
)]
## Positive & Negative Together
with(
sentiment_counts[polarity != 0,],
wordcloud(words = words, freq = n, min.freq = 1,
max.words = 500, random.order = FALSE, rot.per = 0.35,
colors = color, ordered.colors = TRUE, scale = c(5, .75)
)
)
runApp('C:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br')
runApp('C:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br')
?wordcloud
runApp('C:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br')
runApp('C:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br')
runApp('C:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br')
runApp('C:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br')
shiny::runApp('C:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br')
shiny::runApp('C:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br')
rm(list = ls())
library(rvest)
library(ggplot2)
library(plotly)
library(lubridate)
library(scales)
library(plotly)
library(geobr)
library(sf)
library(dplyr)
library(car)
library(chron)
library(TTR)
url <- "https://brasil.io/dataset/covid19/caso_full/?format=csv"
covid <- read.csv(file=url, encoding = "UTF-8")
rm(list = ls())
library(rvest)
library(ggplot2)
library(plotly)
library(lubridate)
library(scales)
library(geobr)
library(sf)
library(plotly)
library(dplyr)
library(car)
library(chron)
library(TTR)
setwd("c:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br/")
url <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-ac.csv"
sintomas_AC <- read.csv(file=url, header = F, sep = ";")
colnames(sintomas_AC) <- c("cod.", "data.notificação", "data.sintomas", "data.nasc", "sintomas",
"profis.saúde", "cbo", "condições", "Teste", "Data.Teste", "Tipo Teste", "Resultado", "País.Or",
"sexo", "bairro", "estado", "município", "cep", "origem", "cnes", "Estado.Notificação",
"municipio.notif", "número.notif", "excluido", "validado", "idade", "data.encerramento",
"evolução", "Classificação.Final")
sintomas_AC <- sintomas_AC[-1,]
confirm_AC <- sintomas_AC %>%
filter(evolução == "Óbito")
a <- round(sum(confirm_AC$sexo == "Masculino")/length(confirm_AC$sexo)*100,1)
b <- round(sum(confirm_AC$sexo == "Feminino")/length(confirm_AC$sexo)*100,1)
#Sexo
ggplot(confirm_AC, aes(x = "", y = sexo, fill = sexo)) +
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start=0) +
annotate("text", x = "", y = 75, label = paste(a, "%")) +
annotate("text", x = "", y = 300, label = paste(b, "%")) +
ggplot(confirm_AC, aes(x = sexo ,  group = sexo)) +
geom_bar(aes(y = ..prop.., stat="identity"))
#Sexo
ggplot(confirm_AC, aes(x = "", y = sexo, fill = sexo)) +
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start=0) +
annotate("text", x = "", y = 75, label = paste(a, "%")) +
annotate("text", x = "", y = 300, label = paste(b, "%"))
no_axis <- theme(axis.title=element_blank(),
axis.text=element_blank(),
axis.ticks=element_blank())
#Sexo
ggplot(confirm_AC, aes(x = "", y = sexo, fill = sexo)) +
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start=0) +
annotate("text", x = "", y = 75, label = paste(a, "%")) +
annotate("text", x = "", y = 300, label = paste(b, "%")) +
no_axis
#Sexo
ggplot(confirm_AC, aes(x = "", y = sexo, fill = sexo)) +
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start=0) +
annotate("text", x = "", y = 75, label = paste(a, "%")) +
annotate("text", x = "", y = 300, label = paste(b, "%")) +
no_axis +
theme_bw()
#Sexo
ggplot(confirm_AC, aes(x = "", y = sexo, fill = sexo)) +
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start=0) +
annotate("text", x = "", y = 75, label = paste(a, "%")) +
annotate("text", x = "", y = 300, label = paste(b, "%")) +
no_axis +
theme_minimal()
no_axis <- theme(axis.title=element_blank(),
axis.text=element_blank(),
axis.ticks=element_blank(),
theme_minimal())
#Sexo
ggplot(confirm_AC, aes(x = "", y = sexo, fill = sexo)) +
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start=0) +
annotate("text", x = "", y = 75, label = paste(a, "%")) +
annotate("text", x = "", y = 300, label = paste(b, "%")) +
no_axis
#Sexo
ggplot(confirm_AC, aes(x = "", y = sexo, fill = sexo)) +
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start=0) +
annotate("text", x = "", y = 75, label = paste(a, "%")) +
annotate("text", x = "", y = 300, label = paste(b, "%")) +
no_axis +
theme_minimal()
#Sexo
ggplot(confirm_AC, aes(x = "", y = sexo, fill = sexo)) +
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start=0) +
annotate("text", x = "", y = 75, label = paste(a, "%")) +
annotate("text", x = "", y = 300, label = paste(b, "%")) +
no_axis
no_axis <- theme(axis.title=element_blank(),
axis.text=element_blank(),
axis.ticks=element_blank())
#Sexo
ggplot(confirm_AC, aes(x = "", y = sexo, fill = sexo)) +
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start=0) +
annotate("text", x = "", y = 75, label = paste(a, "%")) +
annotate("text", x = "", y = 300, label = paste(b, "%")) +
no_axis
no_axis <- theme(axis.title=element_blank(),
axis.text=element_blank(),
axis.ticks=element_blank(),
panel.background = element_blank())
#Sexo
ggplot(confirm_AC, aes(x = "", y = sexo, fill = sexo)) +
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start=0) +
annotate("text", x = "", y = 75, label = paste(a, "%")) +
annotate("text", x = "", y = 300, label = paste(b, "%")) +
no_axis
#Sexo
ggplot(confirm_AC, aes(x = "", y = sexo, fill = sexo)) +
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start=0) +
annotate("text", x = "", y = 75, label = paste(a, "%")) +
annotate("text", x = "", y = 330, label = paste(b, "%")) +
no_axis
urlAC <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-ac.csv"
urlAL <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-al.csv"
urlAP <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-ap.csv"
urlAM <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-am.csv"
urlBA <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-ba.csv"
urlCE <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-ce.csv"
urlDF <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-df.csv"
urlES <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-es.csv"
urlGO <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-go.csv"
urlMA <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-ma.csv"
urlMT <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-mt.csv"
urlMS <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-ms.csv"
urlMG <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-mg.csv"
urlPA <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-pa.csv"
urlPB <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-pb.csv"
urlPR <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-pr.csv"
urlPE <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-pe.csv"
urlPI <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-pi.csv"
urlRJ <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-rj.csv"
urlRN <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-rn.csv"
urlRS <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-rs.csv"
urlRO <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-ro.csv"
urlRR <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-rr.csv"
urlSC <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-sc.csv"
urlSP <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-sp.csv"
urlSE <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-se.csv"
urlTO <- "https://s3-sa-east-1.amazonaws.com/ckan.saude.gov.br/dados-to.csv"
sintomas_AC <- read.csv(file = urlAC, header = F, sep = ";")
sintomas_AL <- read.csv(file = urlAL, header = F, sep = ";")
sintomas_AL <- read.csv(file = urlAL, header = F, sep = ";")
sintomas_AP <- read.csv(file = urlAP, header = F, sep = ";")
sintomas_AM <- read.csv(file = urlAM, header = F, sep = ";")
sintomas_BA <- read.csv(file = urlBA, header = F, sep = ";")
shiny::runApp('C:/Users/Marcelo/Desktop/Data_Science/Data-Science-Specialization/Data products/Course Project/Covid_Br')
